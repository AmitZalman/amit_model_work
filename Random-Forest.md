# Random Forest – סיכום שאלות ותשובות

---

## שאלה 1:  
**האם מודל Random Forest פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?**

**תשובה:**  
גם קלסיפיקציה וגם רגרסיה.

---

## שאלה 2:  
**מהו הרעיון המרכזי שעליו מבוסס מודל Random Forest?**

**תשובה:**  
Random Forest מבוסס על יצירת אוסף (יער) של עצי החלטה רבים.  
המטרה היא להתגבר על החסרונות של עץ החלטה בודד,  
כמו Overfitting או תלות גבוהה בפיצ’רים מסוימים,  
באמצעות שילוב של מספר מודלים שונים.

---

## שאלה 3:  
**כיצד Random Forest קשור למודל Decision Tree?**

**תשובה:**  
Random Forest בנוי ממספר רב של Decision Trees,  
כאשר כל עץ מאומן באופן עצמאי על תת־קבוצה שונה של הנתונים  
ותת־קבוצה אקראית של פיצ’רים.

---

## שאלה 4:  
**מהו Bootstrap Sampling וכיצד הוא משמש ב־Random Forest?**

**תשובה:**  
Bootstrap Sampling הוא תהליך שבו כל עץ מאומן על מדגם אקראי  
של הנתונים עם החזרה (sampling with replacement).  
כך כל עץ רואה סט נתונים שונה במקצת.

---

## שאלה 5:  
**מדוע השימוש באקראיות משפר את ביצועי המודל?**

**תשובה:**  
האקראיות יוצרת עצים מגוונים ופחות מתואמים זה עם זה.  
שילוב התחזיות של עצים שונים מפחית שונות (variance)  
ומקטין את הסיכון ל־Overfitting.

---

## שאלה 6:  
**כיצד מתקבלת התחזית הסופית ב־Random Forest לקלסיפיקציה?**

**תשובה:**  
באמצעות הצבעת רוב (Majority Voting)  
בין התחזיות של כל העצים ביער.

---

## שאלה 7:  
**מהו מנגנון ההצבעה (Voting) ב־Random Forest וכיצד הוא פועל?**

**תשובה:**  
כל עץ מצביע למחלקה מסוימת,  
והמחלקה שקיבלה את מספר הקולות הגבוה ביותר  
נבחרת כתחזית הסופית.

---

## שאלה 8:  
**כיצד מתקבלת התחזית הסופית ב־Random Forest לרגרסיה?**

**תשובה:**  
באמצעות ממוצע התחזיות של כל העצים ביער.

---

## שאלה 9:  
**אילו Hyperparameters נפוצים קיימים במודל Random Forest?**

**תשובה:**  
- n_estimators – מספר העצים ביער  
- max_depth – עומק מקסימלי של כל עץ  
- min_samples_split – מינימום דוגמאות לפיצול  
- min_samples_leaf – מינימום דוגמאות בעלה  
- max_features – מספר הפיצ’רים הנבדקים בכל פיצול  

---

## שאלה 10:  
**מהו OOB Error (Out-Of-Bag Error) וכיצד משתמשים בו להערכת המודל?**

**תשובה:**  
OOB Error מחושב על הדוגמאות שלא נבחרו ב־Bootstrap Sampling  
(כ־37% מהנתונים).  
דוגמאות אלו משמשות כסט בדיקה פנימי,  
ומאפשרות הערכת ביצועים בלי צורך ב־Train/Test Split נפרד.

---

## שאלה 11:  
**מה היתרון של Random Forest מבחינת יציבות המודל  
לעומת Decision Tree?**

**תשובה:**  
Random Forest יציב יותר משום שהוא משלב תחזיות של עצים רבים.  
בניגוד לעץ בודד הרגיש לרעש,  
היער מפחית Overfitting ומשפר את יכולת ההכללה.

---

## שאלה 12:  
**אילו מדדי ביצוע מתאימים להערכת מודל Random Forest  
בקלסיפיקציה וברגרסיה?**

**תשובה:**  

**קלסיפיקציה:**  
- Accuracy  
- Confusion Matrix  


**רגרסיה:**  
- MSE  
- RMSE  
- R²  

---
